{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml\n",
    "import newspaper\n",
    "import mitie\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "usatoday = newspaper.build(\"https://www.usatoday.com/\")\n",
    "washpost = newspaper.build(\"https://www.washingtonpost.com/\")\n",
    "atlantic = newspaper.build(\"https://www.theatlantic.com/\")\n",
    "newyorker = newspaper.build(\"https://www.newyorker.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = []\n",
    "for i in range(10):\n",
    "    articles.append(usatoday.articles[i])\n",
    "    articles.append(washpost.articles[i])\n",
    "    articles.append(atlantic.articles[i])\n",
    "    articles.append(newyorker.articles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for article in articles:\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    texts.append((article.title, article.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getenv('HOME') + '/Packages/MITIE/mitielib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [mitie.tokenize(text[1]) for text in texts]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = mitie.named_entity_extractor(os.getenv('HOME') + '/Packages/MITIE/MITIE-models/english/ner_model.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_list = [ner.extract_entities(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[(range(25, 27), 'PERSON', 1.516026975594067)]\n"
     ]
    }
   ],
   "source": [
    "print(len(entities_list[0]))\n",
    "print(entities_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_texts = []\n",
    "for index, entities in enumerate(entities_list):\n",
    "    token = tokens[index]\n",
    "    temp = []\n",
    "    for e in entities:\n",
    "        width = e[0]\n",
    "        tag = e[1]\n",
    "        score = e[2]\n",
    "        score_text = \"{:0.3f}\".format(score)\n",
    "        entity_text = \" \".join(token[i].decode() for i in width)\n",
    "        temp.append(entity_text)\n",
    "        #print(\"   Score: \" + score_text + \": \" + tag + \" \" + entity_text)\n",
    "        \n",
    "    entity_texts.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = [\" \".join(t) for t in entity_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vect.fit_transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_sim = (tfidf * tfidf.T).A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpectralClustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral = SpectralClustering(n_clusters = 10, eigen_solver='lobpcg', affinity='precomputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/princeaker/.local/lib/python3.5/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpectralClustering(affinity='precomputed', assign_labels='kmeans', coef0=1,\n",
       "          degree=3, eigen_solver='lobpcg', eigen_tol=0.0, gamma=1.0,\n",
       "          kernel_params=None, n_clusters=10, n_init=10, n_jobs=1,\n",
       "          n_neighbors=10, random_state=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral.fit(pairwise_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Terms per cluster:\")\n",
    "# for i in __builtins__.range(8):\n",
    "#     print(\"Cluster %d:\" % i),\n",
    "#     T=t[spectral.labels_==i].indices\n",
    "#     for ind in T:\n",
    "#         print(terms[ind])\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8, 6, 0, 7, 8, 2, 1, 6, 8, 2, 6, 9, 6, 6, 6, 6, 0, 6, 2, 6, 5,\n",
       "       1, 6, 6, 7, 1, 6, 6, 3, 6, 7, 3, 6, 1, 1, 1, 4, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {'title': [text[0] for text in texts], 'label':spectral.labels_}\n",
    "df = pd.DataFrame(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why the United States Needs More Immigrants',\n",
       " '“I think I was being sent a message”: U.S. warned U.N. report on poverty in America could have consequences',\n",
       " 'The 3 Reasons the U.S. Health-Care System Is the Worst']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 0].title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Absurdity of Trump Officials Eating at Mexican Restaurants During an Immigration Crisis',\n",
       " 'The Atlantic Politics & Policy Daily: Do U Care?',\n",
       " \"How Do You Know When It's Officially a Trade War?\",\n",
       " 'How Some Immigrant Families Are Avoiding Separation',\n",
       " 'Interrogating Melania Trump’s Statement Jacket and Its Fast-Fashion Fascism',\n",
       " \"'Womp, womp': Speaker's bureau dumps Lewandowski after he mocks migrant with Down syndrome\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 1].title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC orders spinoff of ‘Roseanne’ without Roseanne Barr',\n",
       " \"'Roseanne' spinoff: ABC picks up 'The Conners,' minus Roseanne Barr\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 3].title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scientists warn a huge solar storm could send us back to the dark ages',\n",
       " 'Photos of the Week: Smoggy Santiago, Miniature Taipei, Mermaid Parade',\n",
       " \"Imagine Dragons' Dan Reynolds on HBO doc, and why he's no longer embarrassed to be Mormon\",\n",
       " 'A Physician in South Texas on an Unnerving Encounter with an Eight-Year-Old Boy in Immigration Detention',\n",
       " 'Backup driver in fatal self-driving Uber crash was streaming Hulu',\n",
       " 'Will Erdoğan Cheat His Way to Victory?',\n",
       " 'Octavia Butler’s Prescient Vision of a Zealot Elected to “Make America Great Again”',\n",
       " \"Princess Charlotte is 'obsessed' with fashion\",\n",
       " 'The Outrage Cycle, Italian Style',\n",
       " \"Your sunscreen is probably expired—and it's time to upgrade\",\n",
       " 'Anthony Bourdain’s Moveable Feast',\n",
       " 'The US used to ship 4,000 recyclable containers a day to China. Where will the banned trash go now?',\n",
       " 'Patrick Melrose and the Fall of the English Élite',\n",
       " 'Keystone virus makes first jump from mosquitoes to humans with confirmed case in Florida teen',\n",
       " \"'Jurassic World: Fallen Kingdom' Is a Lifeless Sequel\",\n",
       " 'The Charles Krauthammer I knew']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label == 6].title.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
